# Provider Response Format Comparison

**Quick Answer:** No, cada provider tiene un formato completamente diferente.

**Version:** 0.4.0-dev  
**Last Updated:** 12 de diciembre de 2025

---

## üîç Comparativa R√°pida

| Aspecto | OpenRouter | Ollama | Anthropic | OpenAI |
|---------|------------|--------|-----------|--------|
| **Formato Base** | OpenAI-compatible | Ollama nativo | Anthropic nativo | OpenAI nativo |
| **Token Fields** | `prompt_tokens`, `completion_tokens` | `prompt_eval_count`, `eval_count` | `input_tokens`, `output_tokens` | `prompt_tokens`, `completion_tokens` |
| **Cost Included?** | ‚úÖ Yes (`usage.cost`) | ‚ùå No (local) | ‚ùå No | ‚ùå No |
| **Streaming Format** | SSE chunks | JSON chunks | SSE events | SSE chunks |
| **Usage in Stream?** | ‚úÖ Yes (final chunk) | ‚úÖ Yes (final chunk) | ‚ö†Ô∏è Partial (events) | ‚ö†Ô∏è Varies |
| **Unique Metadata** | `native_tokens_*`, `generation_id` | Durations, `context` array | `stop_reason`, event types | `system_fingerprint` |

---

## üìä Response Structure Details

### 1. OpenRouter (OpenAI-compatible)

```json
{
  "id": "gen-1764826472-VaXunwHtXQNvgDwANzwO",
  "model": "anthropic/claude-sonnet-4.5",
  "object": "chat.completion.chunk",
  "created": 1764826472,
  "choices": [{
    "index": 0,
    "delta": {"role": "assistant", "content": ""},
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 11549,
    "completion_tokens": 1484,
    "total_tokens": 13033,
    "cost": 0.056907
  }
}
```

**Caracter√≠sticas:**
- ‚úÖ **Estandarizado** a formato OpenAI
- ‚úÖ **Cost incluido** por OpenRouter
- ‚úÖ **Compatible** con OpenAI SDK
- ‚ö†Ô∏è Campos opcionales var√≠an por modelo subyacente

**Nuestro mapeo:**
```php
'usage' => [
    'prompt_tokens' => $finalData['usage']['prompt_tokens'],
    'completion_tokens' => $finalData['usage']['completion_tokens'],
],
'cost' => $finalData['usage']['cost'], // ‚Üê Directo de OpenRouter
```

---

### 2. Ollama (Formato Nativo)

```json
{
  "model": "deepseek-coder:6.7b",
  "created_at": "2025-12-04T04:06:54.123Z",
  "response": "Hello! How can I help?",
  "done": true,
  "context": [1234, 5678, 9012],
  "total_duration": 3448000000,
  "load_duration": 123000000,
  "prompt_eval_count": 156,
  "prompt_eval_duration": 810000000,
  "eval_count": 89,
  "eval_duration": 1200000000
}
```

**Caracter√≠sticas:**
- ‚ùå **NO compatible** con formato OpenAI
- ‚úÖ **Duraciones detalladas** (load, eval, total)
- ‚úÖ **Context array** (tokens del prompt)
- ‚ùå **NO cost** (es local/gratuito)
- ‚ö†Ô∏è Campos diferentes: `prompt_eval_count` vs `prompt_tokens`

**Nuestro mapeo:**
```php
'usage' => [
    'prompt_tokens' => $finalData['prompt_eval_count'] ?? 0, // ‚Üê Mapeo manual
    'completion_tokens' => $finalData['eval_count'] ?? 0,    // ‚Üê Mapeo manual
],
'durations' => [ // ‚Üê Metadata √∫nica de Ollama
    'total' => $finalData['total_duration'],
    'load' => $finalData['load_duration'],
    'eval' => $finalData['eval_duration'],
],
```

---

### 3. Anthropic (SSE Events)

```
event: message_start
data: {"type":"message_start","message":{"id":"msg_01XYZ","usage":{"input_tokens":156}}}

event: content_block_delta
data: {"type":"content_block_delta","delta":{"text":"Hello"}}

event: message_delta
data: {"type":"message_delta","usage":{"output_tokens":89},"delta":{"stop_reason":"end_turn"}}
```

**Caracter√≠sticas:**
- ‚ùå **NO compatible** con formato OpenAI
- ‚úÖ **Event-based streaming** (diferente a chunks)
- ‚ö†Ô∏è Campos diferentes: `input_tokens` vs `prompt_tokens`
- ‚ùå **NO cost** incluido
- ‚úÖ **stop_reason** m√°s descriptivo

**Nuestro mapeo:**
```php
'usage' => [
    'prompt_tokens' => $inputTokens,  // ‚Üê De event message_start
    'completion_tokens' => $outputTokens, // ‚Üê De event message_delta
],
'stop_reason' => $stopReason, // ‚Üê end_turn, max_tokens, stop_sequence
```

---

### 4. OpenAI (Referencia)

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion.chunk",
  "created": 1677652288,
  "model": "gpt-4",
  "choices": [{
    "delta": {"content": "Hello"},
    "finish_reason": null
  }],
  "usage": {
    "prompt_tokens": 156,
    "completion_tokens": 89,
    "total_tokens": 245
  }
}
```

**Caracter√≠sticas:**
- ‚úÖ **Formato est√°ndar** (usado por OpenRouter)
- ‚úÖ `system_fingerprint` (√∫nico de OpenAI)
- ‚ùå **NO cost** incluido
- ‚úÖ Compatible con SDK oficial

---

## üîß Diferencias Cr√≠ticas

### Token Field Names

| Provider | Input Field | Output Field | Total Field |
|----------|-------------|--------------|-------------|
| **OpenRouter** | `prompt_tokens` | `completion_tokens` | `total_tokens` |
| **Ollama** | `prompt_eval_count` | `eval_count` | ‚ùå (calculado) |
| **Anthropic** | `input_tokens` | `output_tokens` | ‚ùå (calculado) |
| **OpenAI** | `prompt_tokens` | `completion_tokens` | `total_tokens` |

### Streaming Differences

| Provider | Format | Usage in Stream? | How to Extract |
|----------|--------|------------------|----------------|
| **OpenRouter** | SSE chunks | ‚úÖ Final chunk | `$finalData['usage']` |
| **Ollama** | JSON lines | ‚úÖ Final chunk (`done: true`) | `$finalData['prompt_eval_count']` |
| **Anthropic** | SSE events | ‚ö†Ô∏è Multiple events | Accumulate from `message_start` + `message_delta` |
| **OpenAI** | SSE chunks | ‚ö†Ô∏è Varies | Sometimes in final chunk |

### Cost Tracking

| Provider | Cost Included? | How to Calculate |
|----------|----------------|------------------|
| **OpenRouter** | ‚úÖ Yes | `$response['usage']['cost']` |
| **Ollama** | ‚ùå No (local) | `0.0` (free) |
| **Anthropic** | ‚ùå No | Manual: tokens √ó pricing |
| **OpenAI** | ‚ùå No | Manual: tokens √ó pricing |

---

## üí° Implementation Strategy

### Our Normalization Layer

Cada provider tiene su propio `Provider.php` que normaliza a este formato com√∫n:

```php
return [
    'usage' => [
        'prompt_tokens' => ...,      // Normalizado
        'completion_tokens' => ...,  // Normalizado
        'total_tokens' => ...,       // Normalizado
    ],
    'model' => ...,
    'finish_reason' => ...,
    'cost' => ...,                   // null si no disponible
    'raw_response' => ...,           // Response original completo
];
```

### Provider-Specific Metadata

Adem√°s del formato com√∫n, cada provider guarda metadata √∫nica:

**OpenRouter:**
```php
'generation_id' => $generationId,
'native_tokens_prompt' => ...,
'native_tokens_completion' => ...,
```

**Ollama:**
```php
'durations' => [
    'total' => ...,
    'load' => ...,
    'eval' => ...,
],
'context' => [...],
```

**Anthropic:**
```php
'stop_reason' => ..., // end_turn, max_tokens, etc.
'stop_sequence' => ...,
```

---

## üìù Key Takeaways

1. ‚ùå **NO hay formato universal** entre providers
2. ‚úÖ **Cada provider** requiere mapeo espec√≠fico
3. ‚úÖ **OpenRouter es el m√°s compatible** (usa formato OpenAI)
4. ‚úÖ **raw_response** guarda datos originales para an√°lisis
5. ‚ö†Ô∏è **Cost solo OpenRouter** lo incluye directamente
6. ‚úÖ **Nuestro c√≥digo normaliza** todo a formato com√∫n

---

## üîó Referencias

- **OpenRouter:** [docs/OPENROUTER-RESPONSE-FORMAT.md](./OPENROUTER-RESPONSE-FORMAT.md)
- **Provider Analysis:** [docs/PROVIDER-RESPONSE-ANALYSIS.md](./PROVIDER-RESPONSE-ANALYSIS.md)
- **Code:** `src/Services/Providers/`
  - `OpenRouterProvider.php` - OpenAI-compatible
  - `OllamaProvider.php` - Ollama nativo
  - `AnthropicProvider.php` - SSE events
  - `OpenAIProvider.php` - OpenAI SDK
