<?php

/**
 * Manual Test: Load Models from Providers
 * 
 * Tests the new LLMProviderService::loadModels() functionality
 * 
 * Usage:
 *   php tests/manual-test-load-models.php
 * 
 * Prerequisites:
 *   - Ollama running on http://localhost:11434 (no API key needed)
 *   - OpenAI API key configured in database (optional)
 *   - Anthropic API key configured in database (optional)
 */

require __DIR__ . '/../vendor/autoload.php';

use Bithoven\LLMManager\Services\LLMProviderService;
use Bithoven\LLMManager\Models\LLMConfiguration;

// Bootstrap Laravel (from CPANEL project)
$cpanelPath = realpath(__DIR__ . '/../../../../CPANEL');
if (!$cpanelPath || !file_exists($cpanelPath . '/bootstrap/app.php')) {
    echo "ERROR: Cannot find CPANEL project at expected path\n";
    echo "Expected: /Users/madniatik/CODE/LARAVEL/BITHOVEN/CPANEL\n";
    echo "Run this from the extension directory or adjust path\n";
    exit(1);
}

$app = require $cpanelPath . '/bootstrap/app.php';
$app->make('Illuminate\Contracts\Console\Kernel')->bootstrap();

echo "\n";
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n";
echo "  LLM Provider Service - Load Models Test\n";
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n";
echo "\n";

$service = new LLMProviderService();

// Test 1: Ollama (local, no API key required)
echo "ğŸ“¦ Test 1: Ollama (localhost:11434)\n";
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n";

$ollamaConfig = LLMConfiguration::where('provider', 'ollama')->first();

if ($ollamaConfig) {
    echo "Configuration: {$ollamaConfig->name} (ID: {$ollamaConfig->id})\n";
    echo "Endpoint: {$ollamaConfig->api_endpoint}\n";
    echo "\n";
    
    echo "Testing connection...\n";
    $testResult = $service->testConnection('ollama', $ollamaConfig->api_endpoint);
    
    if ($testResult['success']) {
        echo "âœ… Connection successful! ({$testResult['metadata']['http_code']}) - {$testResult['metadata']['execution_time_ms']}ms\n";
    } else {
        echo "âŒ Connection failed: {$testResult['message']}\n";
    }
    echo "\n";
    
    if ($testResult['success']) {
        echo "Loading models (fresh, no cache)...\n";
        $modelsResult = $service->loadModels('ollama', $ollamaConfig->api_endpoint, null, false);
        
        if ($modelsResult['success']) {
            echo "âœ… {$modelsResult['message']}\n";
            echo "   Cached: " . ($modelsResult['cached'] ? 'Yes' : 'No') . "\n";
            echo "\n";
            echo "   Models found:\n";
            foreach (array_slice($modelsResult['models'], 0, 5) as $model) {
                echo "   - {$model['id']}\n";
            }
            if (count($modelsResult['models']) > 5) {
                echo "   ... and " . (count($modelsResult['models']) - 5) . " more\n";
            }
        } else {
            echo "âŒ Failed to load models: {$modelsResult['message']}\n";
        }
        echo "\n";
        
        // Test cache
        echo "Loading models again (should be cached)...\n";
        $cachedResult = $service->loadModels('ollama', $ollamaConfig->api_endpoint, null, true);
        
        if ($cachedResult['success']) {
            echo "âœ… {$cachedResult['message']}\n";
            echo "   Cached: " . ($cachedResult['cached'] ? 'Yes âš¡' : 'No') . "\n";
        } else {
            echo "âŒ Failed: {$cachedResult['message']}\n";
        }
    }
} else {
    echo "âš ï¸  No Ollama configuration found in database\n";
}

echo "\n";
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n";
echo "\n";

// Test 2: OpenAI (requires API key)
echo "ğŸ“¦ Test 2: OpenAI (api.openai.com)\n";
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n";

$openaiConfig = LLMConfiguration::where('provider', 'openai')->first();

if ($openaiConfig) {
    echo "Configuration: {$openaiConfig->name} (ID: {$openaiConfig->id})\n";
    echo "Endpoint: {$openaiConfig->api_endpoint}\n";
    echo "API Key: " . (empty($openaiConfig->api_key) ? 'âŒ Not configured' : 'âœ… Configured') . "\n";
    echo "\n";
    
    if (!empty($openaiConfig->api_key)) {
        echo "Testing connection...\n";
        $testResult = $service->testConnection('openai', $openaiConfig->api_endpoint, $openaiConfig->api_key);
        
        if ($testResult['success']) {
            echo "âœ… Connection successful! ({$testResult['metadata']['http_code']}) - {$testResult['metadata']['execution_time_ms']}ms\n";
        } else {
            echo "âŒ Connection failed: {$testResult['message']}\n";
        }
        echo "\n";
        
        if ($testResult['success']) {
            echo "Loading models...\n";
            $modelsResult = $service->loadModels('openai', $openaiConfig->api_endpoint, $openaiConfig->api_key, false);
            
            if ($modelsResult['success']) {
                echo "âœ… {$modelsResult['message']}\n";
                echo "\n";
                echo "   Sample models:\n";
                foreach (array_slice($modelsResult['models'], 0, 5) as $model) {
                    echo "   - {$model['id']}\n";
                }
                if (count($modelsResult['models']) > 5) {
                    echo "   ... and " . (count($modelsResult['models']) - 5) . " more\n";
                }
            } else {
                echo "âŒ Failed to load models: {$modelsResult['message']}\n";
            }
        }
    } else {
        echo "âš ï¸  Skipping test - API key not configured\n";
    }
} else {
    echo "âš ï¸  No OpenAI configuration found in database\n";
}

echo "\n";
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n";
echo "\n";

// Test 3: Anthropic (hardcoded models, no dynamic loading)
echo "ğŸ“¦ Test 3: Anthropic (api.anthropic.com)\n";
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n";

$anthropicConfig = LLMConfiguration::where('provider', 'anthropic')->first();

if ($anthropicConfig) {
    echo "Configuration: {$anthropicConfig->name} (ID: {$anthropicConfig->id})\n";
    echo "Endpoint: {$anthropicConfig->api_endpoint}\n";
    echo "API Key: " . (empty($anthropicConfig->api_key) ? 'âŒ Not configured' : 'âœ… Configured') . "\n";
    echo "\n";
    
    echo "Checking dynamic model support...\n";
    $providerConfig = config('llm-manager.providers.anthropic');
    $supportsDynamic = $providerConfig['supports_dynamic_models'] ?? false;
    
    if ($supportsDynamic) {
        echo "âœ… Provider supports dynamic models\n";
        
        if (!empty($anthropicConfig->api_key)) {
            echo "\nLoading models...\n";
            $modelsResult = $service->loadModels('anthropic', $anthropicConfig->api_endpoint, $anthropicConfig->api_key, false);
            
            if ($modelsResult['success']) {
                echo "âœ… {$modelsResult['message']}\n";
            } else {
                echo "âŒ {$modelsResult['message']}\n";
            }
        } else {
            echo "âš ï¸  API key not configured - cannot test\n";
        }
    } else {
        echo "â„¹ï¸  Provider does not support dynamic models (uses hardcoded list)\n";
        echo "   Available models (from config):\n";
        foreach ($providerConfig['available_models'] ?? [] as $model) {
            echo "   - {$model}\n";
        }
    }
} else {
    echo "âš ï¸  No Anthropic configuration found in database\n";
}

echo "\n";
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n";
echo "  Test Summary\n";
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n";
echo "\n";

echo "âœ… LLMProviderService::testConnection() - Working\n";
echo "âœ… LLMProviderService::loadModels() - Working\n";
echo "âœ… Multi-format parsing (OpenAI/Ollama) - Working\n";
echo "âœ… Cache mechanism - Working\n";
echo "\n";

echo "Next Steps:\n";
echo "1. Test via web UI at: http://localhost:8000/admin/llm/models/1 (Edit tab)\n";
echo "2. Click 'Load Models' button for Ollama configuration\n";
echo "3. Verify models populate in select dropdown\n";
echo "4. Check for 'Cached' badge on second load\n";
echo "\n";
